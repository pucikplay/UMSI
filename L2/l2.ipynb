{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d98a4e-9418-4397-8b7a-8088621543bc",
   "metadata": {},
   "source": [
    "# Lista 2\n",
    "\n",
    "## Uczenie maszynowe i sztuczna inteligencja\n",
    "\n",
    "* [Naiwny klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) oraz [Naiwny wielomianowy klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes)\n",
    "* [Tokenizacja](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n",
    "* [Multizbiór słów](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [N-gram](https://en.wikipedia.org/wiki/N-gram), [Bigram](https://en.wikipedia.org/wiki/Bigram), [Trigram](https://en.wikipedia.org/wiki/Trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd6799-47e0-46c6-b8e3-64a0cb60587c",
   "metadata": {},
   "source": [
    "## Wprowadzenie \n",
    "\n",
    "Spamowanie jest jednym z najprostszych ataków w przesyłaniu wiadomości e-mail. Użytkownicy często otrzymują irytujące wiadomości spamowe oraz złośliwe wiadomości phishingowe, subskrybując różne strony internetowe, produkty, usługi, katalogi, biuletyny informacyjne oraz inne rodzaje komunikacji elektronicznej. W niektórych przypadkach, spamowe wiadomości e-mail są generowane przez wirusy lub konie trojańskie rozsyłane masowo.\n",
    "\n",
    "Istnieje wiele rozwiązań do filtrowania spamu, takich jak techniki filtrowania na czarnej i białej liście, podejścia oparte na drzewach decyzyjnych, podejścia oparte na adresach e-mail oraz metody oparte na uczeniu maszynowym. Większość z nich opiera się głównie na analizie tekstu zawartości e-maila. W rezultacie rośnie zapotrzebowanie na skuteczne filtry antyspamowe, które automatycznie identyfikują i usuwają wiadomości spamowe lub ostrzegają użytkowników przed możliwymi wiadomościami spamowymi. Jednak spamerzy zawsze badają luki istniejących technik filtrowania spamu i wprowadzają nowy projekt do rozprzestrzeniania spamu w szerokim zakresie np. atak tokenizacji czasami wprowadza w błąd filtry antyspamowe, dodając dodatkowe spacje. Dlatego też treści e-maili muszą być strukturalizowane. Ponadto, pomimo posiadania najwyższej dokładności w wykrywaniu spamu za pomocą uczenia maszynowego, fałszywe pozytywy (False Positive, FP) stanowią problem z powodu jednorazowego wykrywania zagrożeń e-mailowych. Aby zaradzić problemom z fałszywymi pozytywami oraz zmianom w różnych projektach ataków, z tekstu usuwane są słowa kluczowe oraz inne niepożądane informacje przed dalszą analizą. Po wstępnym przetwarzaniu, te teksty przechodzą przez liczne metody ekstrakcji cech, takie jak word2vec, word n-gram, character n-gram oraz kombinacje n-gramów o zmiennych długościach. Różne techniki uczenia maszynowego, takie jak support vector machine (SVM), decision tree (DT), logistic regression (LR) oraz multinomial naıve bayes (MNB), są stosowany aby dokonać klasyfikacji e-maili.\n",
    "\n",
    "Na tej liste skoncentrujemy się tylko na metodzie naiwnego klasyfikatora bayesowskiego przedstawionego na wykładzie wraz z wersją [wielomianową](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes).\n",
    "\n",
    "#### **Uwaga**\n",
    "\n",
    "**Wszystkie implementacje klasyfikatorów należy napisać samemu. Na tej liście nie korzystamy z implementacji klasyfikatorów istniejących w popularnych bibliotekach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550496e-1cac-4071-935a-6f92eec8afd7",
   "metadata": {},
   "source": [
    "\n",
    "# Klasyfikatory Naiwnego Bayesa (NB)\n",
    "\n",
    "W naszych eksperymentach po wstępnym przetworzeniu każda wiadomość jest ostatecznie reprezentowana jako wektor $\\mathbf{x}=(x_1, \\ldots , x_m)$, gdzie $x_1, \\ldots , x_m$ są wartościami atrybutów $X_1, \\ldots , X_m$ , a każdy atrybut dostarcza informacje o określonym tokenie wiadomości. W najprostszym przypadku wszystkie atrybuty są wartościami boolowskimi: $X_i = 1$, jeśli wiadomość zawiera dany token; w przeciwnym razie, $X_i = 0$. Alternatywnie, ich wartości mogą być częstotliwościami tokenów (TF), pokazującymi, ile razy odpowiadający token występuje w wiadomości. Atrybuty z wartościami TF przenoszą więcej informacji niż atrybuty boolowskie.\n",
    "\n",
    "Z twierdzenia Bayesa wynika, że prawdopodobieństwo, że wiadomość o wektorze $\\mathbf{x} = (x_1, \\ldots, x_m)$ należy do kategorii $c$, wynosi: \n",
    "\n",
    "$$\n",
    "p(c | \\mathbf{x}) = \\frac{p(c) \\cdot p(\\mathbf{x} | c)}{p(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Ponieważ mianownik nie zależy od kategorii, klasyfikator NB klasyfikuje każdą wiadomość do kategorii, która maksymalizuje $p(c) \\cdot p(\\mathbf{x} | c)$. W przypadku filtrowania spamu oznacza to klasyfikowanie wiadomości jako spamu, gdy: \n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot p(\\mathbf{x} | c_s)}{p(c_s) \\cdot p(\\mathbf{x} | c_s) + p(c_h) \\cdot p(\\mathbf{x} | c_h)} > T\n",
    "$$\n",
    "\n",
    "gdzie $T = 0.5$, a $c_h$ i $c_s$ oznaczają kategorie ham i spam. Zmieniając $T$, można zdecydować się na więcej prawdziwych negatywów (poprawnie sklasyfikowane wiadomości ham) kosztem mniej prawdziwych pozytywów (poprawnie sklasyfikowane wiadomości spam), lub odwrotnie. Prawdopodobieństwa a priori $p(c)$ są zwykle szacowane przez podzielenie liczby treningowych wiadomości kategorii $c$ przez łączną liczbę treningowych wiadomości. Prawdopodobieństwa $p(\\mathbf{x} | c)$ są szacowane w różny sposób w każdej wersji NB - patrz wykład.\n",
    "\n",
    "# Naiwny klasyfikator bayesowski wielomianowy (MNB)\n",
    "\n",
    "Klasyfikator [wielomianowy](https://en.wikipedia.org/wiki/Multinomial_distribution) bayesowski z atrybutami TF traktuje każdą wiadomość $d$ jako [multizbiór]((https://en.wikipedia.org/wiki/Bag-of-words_model)) tokenów, zawierający każdy token $t_i$ tyle razy, ile występuje w $d$. Dlatego $d$ można przedstawić jako $\\mathbf{x} = (x_1, ..., x_m)$, gdzie każde $x_i$ to teraz liczba wystąpień $t_i$ w $d$. Ponadto, każda wiadomość $d$ z kategorii $c$ jest postrzegana jako wynik niezależnego wyboru $|d|$ tokenów z $F=\\{t_1,\\ldots,t_m\\}$ z powtórzeniami, z prawdopodobieństwem $p(t_i | c)$ dla każdego $t_i$. Wówczas $p(\\mathbf{x} | c)$ jest rozkładem wielomianowym:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c) = p(|d|) \\cdot |d|! \\cdot \\prod_{i=1}^{d} \\frac{p(t_i \\mid c)^{x_i}}{x_i !}\n",
    "$$\n",
    "\n",
    "gdzie zakładamy, że $|d|$ nie zależy od kategorii $c$. Jest to dodatkowe uproszczające założenie, które jest bardziej dyskusyjne w filtrowaniu spamu. Na przykład, prawdopodobieństwo otrzymania bardzo długiej wiadomości spamowej wydaje się mniejsze niż prawdopodobieństwo otrzymania równie długiej wiadomości ham. Kryterium klasyfikacji wiadomości jako spamu staje się:\n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot \\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i}}{p(c_s)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i} + p(c_h)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_h)^{x_i}}  > T\n",
    "$$\n",
    "\n",
    "gdzie każde $p(t_i | c)$ jest szacowane jako:\n",
    "\n",
    "$$\n",
    "p(t \\mid c) = \\frac{\\alpha + N_{t,c}}{\\alpha \\cdot m + N_c}\n",
    "$$\n",
    "gdzie $N_{t,c}$ to liczba wystąpień tokena $t$ w treningowych wiadomościach kategorii $c$, podczas gdy $N_c = \\sum_{i=1}^{m} N_{t_i,c}$ to łączna liczba wiadomości treningowych kategorii $c$. W praktyce dodaje się jeszcze parametr $\\alpha$ który reprezentuje wygładzenie (smoothing) i rozwiązuje problem zerowego prawdopodobieństwa, patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html) (np. $\\alpha=1$).\n",
    "\n",
    "\n",
    "### Przykładowe dane wielomianowe\n",
    "\n",
    "Zatem każda wiadomość $d$  składa się z różnych tokenów $t_i$, a każde z tych $t_i$ należy do słownika $\\mathcal{V}$. Jeśli $\\mathcal{V}$ zawiera np. $8$ tokenów, $t_1,t_2,...,t_8$, a wiadomość to: $t_1 t_2 t_2 t_6 t_3 t_2 t_8$, reprezentacja tej wiadomości będzie następująca:\n",
    "\n",
    "| |$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|$\\mathbf{x}$| 1|3 |1 | 0| 0|1 | 0|1 |\n",
    "\n",
    "Po dodaniu kilku innych losowych wiadomości, zbiór danych wygląda tak:\n",
    "\n",
    "|$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|$c$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| 1|3 |1 | 0| 0|1 | 0|1 | spam|\n",
    "| 1|0 |0 | 0| 1|1 | 1|3 | ham|\n",
    "| 0|0 |0 | 0| 0|2 | 1|2 | spam|\n",
    "\n",
    "Przyjmując klasy ($1$-spam,$0$-ham) mamy $c = [1,0,1]$. Teraz, porównując z równaniem powyżej,\n",
    "\n",
    "- $N_{t_i,c}$ to liczba wystąpień cechy $t_i$ w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_{t_1,c}=1, N_{t_6,c}=3$\n",
    "- $N_c$ to całkowita liczba wystąpień wszystkich cech w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_c=12$\n",
    "- $m=8$ to całkowita liczba cech\n",
    "- $\\alpha=1$ jest znany jako parametr wygładzania. Jest on potrzebny do problemu zerowego prawdopodobieństwa (patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html))\n",
    "\n",
    "# Niedomiar zmiennoprzecinkowy (floating point underflow)\n",
    "\n",
    "Aby uniknąć problemu niedomiaru zmiennoprzecinkowego, mnożenie zbioru małych prawdopodobieństw, czyli po prostu iloczyn stanie się zbyt mały, aby go reprezentować i zostanie zastąpiony przez 0. Zamiast obliczać\n",
    "$$\n",
    "P(c) \\prod_{i=1}^m P(t_i | c)\n",
    "$$\n",
    "co może spowodować niedomiar, rozważmy obliczenie logarytmu tego wyrażenia,\n",
    "$$\n",
    "\\log\\left(P(c) \\prod_{i=1}^m P(t_i | c)\\right)\n",
    "$$\n",
    "co równoważnie można zapisać jako\n",
    "$$\n",
    "\\log(P(c))+ \\sum_{i=1}^m \\log(P(t_i | c))\n",
    "$$\n",
    "Następnie zauważ, że jeśli\n",
    "$$\n",
    "\\log(P(c_s))+ \\sum_{i=1}^m \\log(P(t_i | c_s)) > \\log(P(c_h))+ \\sum_{i=1}^m \\log(P(t_i | c_h))\n",
    "$$\n",
    "wtedy, ponieważ $\\log(x) > \\log(y)$ iff $x > y$, to\n",
    "$$\n",
    "P(c_s) \\prod_{i=1}^m P(t_i | c_s) > P(c_h) \\prod_{i=1}^m P(t_i | c_h)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff1e5a-8599-412a-9494-45699a65a2fb",
   "metadata": {},
   "source": [
    "## Zadanie 1 (10pt)\n",
    "\n",
    "### Klasyfikator oparty na algorytmie NB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować prosty klasyfikator spamu oparty na NB, który będzie w stanie wykryć i odfiltrować niechciane wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tokenizację słów i usuń zbędne znaki interpunkcyjne.\n",
    "3. Zaimplementuj NB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam na podstawie występujących słów.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator NB na danych treningowych.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i przedstaw wnioski.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db03424-f98e-4b03-8cb3-cbb1cb5d4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "sms_df = pd.read_csv('sms+spam+collection/SMSSpamCollection', delimiter='\\t', names=['label', 'text'])\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f3b46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fast.pls',\n",
       " 'WKEND',\n",
       " 'To',\n",
       " 'empty',\n",
       " 'tech',\n",
       " 'kisi',\n",
       " 'jobs',\n",
       " 'off,',\n",
       " 'INK',\n",
       " 'western']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_text(df):\n",
    "    df['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "    return df\n",
    "    # text = df['text'].values\n",
    "    # lower_text = list(map(lambda x: x.lower(), text))\n",
    "    # clean_text = list(map(lambda x: re.sub(\"[^a-z]+\", \" \", x), lower_text))\n",
    "    # return df.assign(text=clean_text)\n",
    "\n",
    "def get_tokens(df):\n",
    "    text = df['text'].values\n",
    "    return list(set(' '.join(text).split()))\n",
    "\n",
    "sms_df = prepare_text(sms_df)\n",
    "get_tokens(sms_df)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feb290fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.cond_probs = {}\n",
    "\n",
    "    def train(self, df):\n",
    "        for token in get_tokens(df):\n",
    "            ham_count = sum(df['label'] == 'ham')\n",
    "            spam_count = sum(df['label'] == 'spam')\n",
    "            self.class_probs = { \n",
    "                'ham': ham_count / len(df),\n",
    "                'spam': spam_count / len(df)\n",
    "            }\n",
    "            self.cond_probs[token] = {\n",
    "                # sum(class and token) / sum(class)\n",
    "                # +1 to avoid 0 probability\n",
    "                'ham': (sum((df['label'] == 'ham') &\n",
    "                            (df['text'].str.contains(token))) + 1) /\n",
    "                       (ham_count + 1),\n",
    "                'spam': (sum((df['label'] == 'spam') &\n",
    "                             (df['text'].str.contains(token))) + 1) /\n",
    "                        (spam_count + 1)\n",
    "            }\n",
    "\n",
    "    def predict(self, message):\n",
    "        tokens = message.split()\n",
    "        # to avoid floating point underflow use log\n",
    "        ham_prob = np.log(self.class_probs['ham'])\n",
    "        spam_prob = np.log(self.class_probs['spam'])\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in self.cond_probs:\n",
    "                ham_prob += np.log(self.cond_probs[token]['ham'])\n",
    "                spam_prob += np.log(self.cond_probs[token]['spam'])\n",
    "\n",
    "        if spam_prob > ham_prob:\n",
    "            return 'spam'\n",
    "        else:\n",
    "            return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee4a267",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unbalanced parenthesis at position 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m sms_df[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m      5\u001b[0m nb \u001b[38;5;241m=\u001b[39m NaiveBayes()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m, in \u001b[0;36mNaiveBayes.train\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m      9\u001b[0m spam_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_probs \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m: ham_count \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(df),\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m: spam_count \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(df)\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_probs[token] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# sum(class and token) / sum(class)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# +1 to avoid 0 probability\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;28msum\u001b[39m((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m---> 18\u001b[0m                 (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\n\u001b[0;32m     19\u001b[0m            (ham_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;28msum\u001b[39m((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspam\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     21\u001b[0m                  (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(token))) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\n\u001b[0;32m     22\u001b[0m             (spam_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:128\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:1238\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains\u001b[39m(\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28mself\u001b[39m, pat, case: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, regex: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m ):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;124;03m    Test if pattern or regex is contained within a string of a Series or Index.\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m regex \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroups:\n\u001b[0;32m   1239\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1240\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1242\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1243\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1244\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:227\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_compiler.py:743\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    742\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 743\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    745\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_parser.py:985\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munbalanced parenthesis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mgrouprefpos:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mgroups:\n",
      "\u001b[1;31merror\u001b[0m: unbalanced parenthesis at position 8"
     ]
    }
   ],
   "source": [
    "mask = np.random.rand(len(sms_df)) < 0.7\n",
    "train = sms_df[mask]\n",
    "test = sms_df[~mask]\n",
    "\n",
    "nb = NaiveBayes()\n",
    "nb.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties(nb, df):\n",
    "    # true values, then how predicted\n",
    "    values = {'ham': {'ham': 0, 'spam': 0},\n",
    "              'spam': {'ham': 0, 'spam': 0}}\n",
    "    true_vals = df['label']\n",
    "    pred_vals = df['text'].apply(nb.predict)\n",
    "    for (true_val, pred_val) in zip(true_vals, pred_vals):\n",
    "        values[true_val][pred_val] += 1\n",
    "\n",
    "    accuracy = (values['ham']['ham'] + values['spam']['spam']) / len(df)\n",
    "    precision = values['spam']['spam'] / (values['spam']['spam'] + values['ham']['spam'])\n",
    "    recall = values['spam']['spam'] / (values['spam']['spam'] + values['spam']['ham'])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    result = {'accuracy': accuracy,\n",
    "              'precision': precision,\n",
    "              'recall': recall,\n",
    "              'f1': f1}\n",
    "    return result\n",
    "\n",
    "properties(nb, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_properties(result_train, result_test):\n",
    "    fig, axs = plt.subplots(1,4, figsize=(10,10))\n",
    "\n",
    "    axs[0].bar(['Train', 'Test'], [result_train['accuracy'], result_test['accuracy']])\n",
    "    axs[0].set_title('Accuracy')\n",
    "\n",
    "    axs[1].bar(['Train', 'Test'], [result_train['precision'], result_test['precision']])\n",
    "    axs[1].set_title('Precision')\n",
    "\n",
    "    axs[2].bar(['Train', 'Test'], [result_train['recall'], result_test['recall']])\n",
    "    axs[2].set_title('Recall')\n",
    "\n",
    "    axs[3].bar(['Train', 'Test'], [result_train['f1'], result_test['f1']])\n",
    "    axs[3].set_title('F1 Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "result_train = properties(nb, train)\n",
    "result_test = properties(nb, test)\n",
    "plot_properties(result_train, result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a933bb-c803-4e52-a562-e2a47944fb5f",
   "metadata": {},
   "source": [
    "## Zadanie 2 (15pt)\n",
    "\n",
    "### Klasyfikator oparty na n-gramach MNB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować klasyfikator spamu, wykorzystując n-gramy w połączeniu MNB, aby poprawić skuteczność klasyficji wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tworzenie n-gramów z treści wiadomości e-mail tzn. unigramy, bigramy, trigramy.\n",
    "3. Zaimplementuj MNB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam, wykorzystując n-gramy jako cechy.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator MNB na danych treningowych, wykorzystując n-gramy jako cechy.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i porównaj je z wynikami klasyfikatora opartego na słowach.\n",
    "8. Przedstaw wnioski dotyczące skuteczności klasyfikatora opartego na n-gramach oraz wpływu różnych typów n-gramów na skuteczność klasyfikacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ff309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_n_grams(df, n):\n",
    "#     vectorizer = CountVectorizer(ngram_range=(1,n))\n",
    "#     X = vectorizer.fit_transform(df['text'])\n",
    "#     return vectorizer, X\n",
    "\n",
    "# vectorizer, X = get_n_grams(sms_df, 2)\n",
    "# vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2135aa-3e93-4bd9-8d6d-467f14e29f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultinomialNaiveBayes:\n",
    "#     def __init__(self, gram_len, alpha=1):\n",
    "#         self.class_probs = {}\n",
    "#         self.cond_probs = {}\n",
    "#         self.n = gram_len\n",
    "#         self.alpha = alpha\n",
    "\n",
    "#     def train(self, df):\n",
    "#         self.class_probs = { \n",
    "#             'ham': sum(df['label'] == 'ham') / len(df),\n",
    "#             'spam': sum(df['label'] == 'spam') / len(df)\n",
    "#         }\n",
    "\n",
    "#         self.vectorizer, X = get_n_grams(df, self.n)\n",
    "#         feature_names = self.vectorizer.get_feature_names_out()\n",
    "#         m = len(feature_names)\n",
    "\n",
    "#         N_c_ham = sum(X[df['label'] == 'ham'].toarray().ravel())\n",
    "#         N_c_spam = sum(X[df['label'] == 'spam'].toarray().ravel())\n",
    "\n",
    "#         for token in feature_names:\n",
    "#             token_idx = np.where(feature_names == token)[0][0]\n",
    "#             N_tc_ham = X[df['label'] == 'ham', token_idx].sum()\n",
    "#             N_tc_spam = X[df['label'] == 'spam', token_idx].sum()\n",
    "\n",
    "#             self.cond_probs[token] = {\n",
    "#                 'ham': (self.alpha + N_tc_ham) / (self.alpha * m + N_c_ham),\n",
    "#                 'spam': (self.alpha + N_tc_spam) / (self.alpha * m + N_c_spam)\n",
    "#             }\n",
    "\n",
    "#     def predict(self, message):\n",
    "#         X = self.vectorizer.transform([message])\n",
    "#         feature_names = self.vectorizer.get_feature_names_out()\n",
    "\n",
    "#         # to avoid floating point underflow use log\n",
    "#         ham_prob = np.log(self.class_probs['ham'])\n",
    "#         spam_prob = np.log(self.class_probs['spam'])\n",
    "\n",
    "#         for token_idx in X.indices:\n",
    "#             token = feature_names[token_idx]\n",
    "#             for token in self.cond_probs:\n",
    "#                 ham_prob += np.log(self.cond_probs[token]['ham'])\n",
    "#                 spam_prob += np.log(self.cond_probs[token]['spam'])\n",
    "        \n",
    "#         if spam_prob > ham_prob:\n",
    "#             return 'spam'\n",
    "#         else:\n",
    "#             return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86465f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_df = pd.read_csv('sms+spam+collection/SMSSpamCollection', delimiter='\\t', names=['label', 'text'])\n",
    "# sms_df = prepare_text(sms_df)\n",
    "\n",
    "# mask = np.random.rand(len(sms_df)) < 0.7\n",
    "# train = sms_df[mask]\n",
    "# test = sms_df[~mask]\n",
    "\n",
    "# nb = MultinomialNaiveBayes(2)\n",
    "# nb.train(train)\n",
    "# properties(nb, test)\n",
    "# for i in [2,3]:\n",
    "#     nb = MultinomialNaiveBayes(i)\n",
    "#     nb.train(train)\n",
    "#     result_train = properties(nb, train)\n",
    "#     result_test = properties(nb, test)\n",
    "#     plot_properties(result_train, result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
